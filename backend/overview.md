# AI 강아지 자세 추적 기능 분석 (YOLOv8 기반)

## 1. 개요

이 문서는 Pet-Life Magazine 프로젝트의 핵심 AI 기능 중 하나인 '강아지 자세 추적' 기능의 기술적 구성, 개발 과정, 현재 상태 및 향후 계획을 정리한 개요서입니다.

- **핵심 기능:** 사용자가 업로드한 동영상에서 AI 모델을 통해 강아지의 주요 관절(Keypoints)을 실시간으로 추적하고, 그 움직임을 시각적으로 분석하여 스켈레톤 형태의 오버레이를 입힌 영상을 제공합니다.
- **기대 효과:** 반려견의 미묘한 자세 변화, 걸음걸이 불균형, 활동량 등을 데이터 기반으로 분석하여 잠재적인 건강 문제를 조기에 발견할 수 있도록 돕습니다.

## 2. 기술 아키텍처

- **핵심 모델:** **YOLOv8 (Pose Estimation 모델)**
  - **프로토타입:** `yolov8n-pose.pt` (범용 모델)
  - **최종 모델:** `best.pt` (강아지 전용 데이터셋으로 파인튜닝된 전문가 모델)
- **학습 환경:** **Google Colab**
  - 고성능 GPU를 활용하여 모델 학습 및 프로토타이핑을 진행했습니다.
  - Colab의 런타임 중단 문제를 해결하기 위해, Google Drive를 연동한 **'학습 이어하��(resume)' 워크플로우**를 구축하여 안정적인 학습을 보장했습니다.
- **데이터셋:** `dog-pose` 데이터셋 (Kaggle, Ultralytics 공식 YAML)
- **백엔드 처리 (예상):** Python 기반 서버 (Flask/FastAPI)
  - `best.pt` 모델을 로드하고, `OpenCV`를 사용하여 동영상 파일을 프레임 단위로 처리 및 인코딩합니다.
- **최종 산출물:** 모델 가중치 파일 **`best.pt`**

## 3. 개발 히스토리 및 주요 장애물 해결

- **Phase 1: Colab 환경 설정 및 프로토타이핑 (Day 12)**
  - **환경 구축:** `!pip install ultralytics`를 통해 Colab에 라이브러리를 설치하고, `yolov8n-pose.pt` 범용 모델을 로드하여 초기 환경을 설정했습니다.
  - **초기 검증:** 범용 모델을 사용하여 샘플 영상 분석 및 스켈레톤 시각화의 기술적 가능성을 확인했으나, 정확도가 매우 낮아 강아지 전용 '전문가 모델'의 필요성을 인지했습니다.
  - **장애물 1: 데이터 포맷 불일치:** 공식 `dog-pose` 데이터셋 학습 시, 라벨 데이터가 표준(53열)과 다른 77열 형식(`x, y, visibility`)인 것을 발견했습니다.
  - **해결:** 불필요한 `visibility` 값을 제거하는 **데이터 전처리 스크립트**를 작성하여 전체 데이터셋을 학습 가능한 포맷으로 정제했습니다.
  - **장애물 2: Colab 런타임 중단:** 50 에포크 학습 도중 34 에포크에서 런타임이 중단되어 진행 상황이 소실되는 문제를 겪었습니다.

- **Phase 2: '학습 이어하기' 워크플로우 구축 및 모델 학습 (Day 14)**
  - **Google Drive 연동:** `drive.mount('/content/drive')`를 통해 Colab과 Google Drive를 연동하여, 학습 결과물(가중치, 로그)이 영구적으로 저장될 수 있는 기반을 마련했습니다.
  - **'이어하기' 로직 구현:** 학습 스크립트에 `os.path.exists`를 사용하여 Google Drive에 저장된 마지막 체크포인트(`last.pt`)의 존재 여부를 확인하고, 있을 경우 `resume=True` 옵션으로 학습을 재개하는 로직을 구현했습니다.
  - **해결:** 이 **'학습 이어하기' 워크플로우**를 통해 런타임 중단 문제를 근본적으로 해결하고, 20 에포크 학습을 성공적으로 완료하여 최종 모델인 `best.pt`를 확보했습니다.
  - **핵심 자산 식별:** 웹 서비스 배포에 필요한 것은 오직 Google Drive에 저장된 `best.pt` 파일 하나임을 명확히 했습니다.

- **Phase 3: 모델 검증 및 웹 연동 MVP 완성 (Day 15)**
  - **추론 및 검증:** 학습된 `best.pt` 모델을 로드하고, 사용자가 업로드한 영상에 대해 `model.predict()`를 실행하여 스켈레톤 추론 ���능을 검증했습니다. 결과 영상은 노트북에 `IPython.display.Video`로 직접 표시하여 시각적으로 확인했습니다.
  - **장애물 3: 웹 영상 재생 문제:** 백엔드에서 처리된 영상이 웹 브라우저에서 재생되지 않는 문제를 발견했습니다.
  - **해결:** `OpenCV`의 `VideoWriter`를 사용하여 영상 코덱을 웹 표준인 **H.264 (avc1)**로 명시적으로 인코딩하여 문제를 해결했습니다.

## 4. 현재 상태 및 알려진 한계

- **현재 상태:** 'AI 자세 분석' 기능의 MVP(최소 기능 제품)가 완성된 상태입니다. 사용자가 영상을 업로드하면, 분석된 스켈레톤 영상을 확인할 수 있습니다.
- **알려진 한계:**
  - **데이터 편향성:** 현재 모델(`best.pt`)은 **옆모습(side profile)** 데이터 위주로 학습되었습니다.
  - **성능 저하:** 이로 인해, 강아지의 **앞모습이나 뒷모습 영상**에 대해서는 관절 추적 성능이 현저히 떨어지거나 거의 작동하지 않습니다.

## 5. 향후 계획 및 전략적 목표

- **단기 목표:** 현재의 한계점을 사용자에게 명확히 인지시키고(예: "옆모습 영상을 올려주세요"), 제한된 환경에서라도 안정적인 서비스를 제공합니다.
- **장기 전략: 단일 '슈퍼 모델' 개발**
  - **문제 해���:** 각도별로 여러 모델을 만드는 것은 사용자에게 불편을 초래하므로, 장기적으로는 바람직하지 않습니다.
  - **최적의 해결책:** **모든 각도(앞, 뒤, 옆)와 다양한 자세의 데이터를 모두 통합**하여, 어떤 상황에서도 강인하게 작동하는 **단 하나의 '슈퍼 모델'**을 학습시키는 것을 최종 목표로 합니다. 이는 사용자에게 최고의 편의성과 정확도를 제공하는 가장 이상적인 전략입니다.

---

## 6. Hugging Face 배포 기록

- **Phase 1: 로컬 프로젝트 준비 (완료)**
  - **폴더 구조 정리:** `backend/models` 폴더를 생성하고 `best.pt` 모델을 이동하여 프로젝트 구조를 정리했습니다.
  - **의존성 파일 준비:** `requirements.txt` 파일을 검토하고, `opencv-python-headless`와 `gunicorn` 등 프로덕션 환경에 필요한 라이브러리를 확정했습니다.
  - **코드 수정:** `main.py`의 `uvicorn.run()` 직접 실행 부분을 주석 처리하여 배포 환경에 맞게 수정했습니다.

- **Phase 2: Hugging Face Space 생성 및 설정 (완료)**
  - `juyoungkim/dogpose` 이름으로 신규 Space를 생성했습니다.
  - **SDK:** Docker (Blank)
  - **Hardware:** T4-small (무료 GPU)
  - **Secrets 설정:** `SUPABASE_URL`과 `SUPABASE_SERVICE_KEY`를 Space의 Secrets에 안���하게 등록했습니다.

- **Phase 3: 런타임 오류 해결 (완료)**
  - **1차 오류 (시스템 라이브러리 누락):** `ImportError: libGL.so.1` 오류 발생. `Dockerfile`에 `RUN apt-get install -y libgl1-mesa-glx`를 추가하여 OpenCV의 시스템 의존성을 해결했습니다.
  - **2차 오류 (폴더 생성 권한):** `PermissionError: [Errno 13] Permission denied` 오류 발생. `Dockerfile`에 `RUN mkdir -p ... && chmod -R 777 ...` 구문을 추가하여, 코드 실행 전에 미리 폴더를 만들고 쓰기 권한을 부여하여 해결했습니다.
  - **3차 오류 (모델 파일 경로):** `FileNotFoundError` 및 `IsADirectoryError`가 반복적으로 발생. 원인은 Hugging Face Space에 업로드된 모델 파일의 경로와 코드(`main.py`)가 참조하는 경로가 일치하지 않았기 때문입니다.
  - **최종 해결:** Space의 파일 구조를 `models/best.pt`로 단순화하고, `main.py`의 모델 로드 경로를 `os.path.join(current_dir, "models", "best.pt")`로 명확하게 수정하여 문제를 최종 해결했습니다.

---

## 7. 아키텍처 개선 및 배포 안정화 (Day 16)

배포 성공 이후, 실제 운영 환경(`mungai.co.kr`)에서 프론트엔드와 연동 시 `ERR_NETWORK` 오류가 지속적으로 발생하여, 근본적인 원인 해결을 위한 대규모 디버깅 및 아키���처 개선을 진행했습니다.

- **Phase 1: 클라이언트 렌더링 아키텍처로 전환**
  - **문제 인식:** 서버에서 동영상을 인코딩하는 방식은 코덱 의존성이 높고 서버 부하가 커, 배포 환경에서 잠재적 오류 발생 가능성이 높다고 판단했습니다.
  - **해결:** 서버는 더 이상 결과 비디오를 만들지 않고, **원본 비디오 URL**과 **프레임별 관절 좌표(JSON)**만 반환하도록 백엔드(`main.py`)를 수정했습니다. 프론트엔드(`PostureAnalysisPage.tsx`)는 이 데이터를 받아 HTML `<canvas>`를 이용해 실시간으로 스켈레톤을 그리도록 로직을 완전히 변경했습니다. 이로써 서버의 코덱 의존성과 부하 문제를 원천적으로 제거했습니다.

- **Phase 2: `ERR_NETWORK` 오류 심층 디버깅**
  - **1차 원인 (CORS 오류):** 브라우저가 다른 출처(Cross-Origin)의 API 요청을 차단하는 문제를 발견했습니다.
  - **해결:** 백엔드의 `CORSMiddleware` 설정을 `allow_origins=["*"]`에서 실제 운영 도메인(`https://mungai.co.kr`)과 로컬 개발 주소를 명시적으로 지정하는 방식으로 변경하여 보안과 안정성을 높였습니다.
  
  - **2차 원인 (잘못된 API 주소):** 프론트엔드가 운영 환경에서도 로컬 주소(`http://127.0.0.1:8000`)�� 호출하고 있었음을 발견했습니다.
  - **해결:** Vite의 **환경 변수** 시스템을 도입했습니다. `.env.development`와 `.env.production` 파일을 생성하여 개발/운영 API 주소를 분리하고, 코드에서는 `import.meta.env.VITE_API_BASE_URL`을 사용하도록 수정하여 문제를 해결했습니다.
  
  - **3차 원인 (혼합 콘텐츠 오류):** 운영 환경(`https`)에서 `http`로 된 API 응답 URL을 호출하여 브라우저에 의해 차단되는 문제를 확인했습니다.
  - **해결:** 백엔드에서 `x-forwarded-proto` 헤더를 확인하여, 리버스 프록시 환경에서도 항상 올바른 `https://` URL을 생성하도록 로직을 수정했습니다.

- **Phase 3: 타임아웃 문제 해결을 위한 비동기 아키텍처 도입**
  - **최종 원인 (타임아웃):** 모든 문제를 해결했음에도 7초 길이의 영상에서 오류가 발생하는 것을 통해, 근본 원인이 Vercel/Netlify 등 프론트엔드 호스팅 플랫폼의 **요청 처리 시간 제한(약 10초)** 때문임을 최종적으로 규명했습니다. AI 분석 시간이 이 제한을 초과하여 연결이 강제로 끊겼던 것입니다.
  - **최종 해결 (비동기 작업 + 폴링):** 하나의 긴 요청을 여러 개의 짧은 요청으로 나누는 **비동기 작업 아키텍처**를 전면 도입했습���다.
    1.  **백엔드:** FastAPI의 `BackgroundTasks`를 사용하여 AI 분석을 백그라운드에서 처리하고, 작업 상태를 확인할 수 있는 API(`POST /api/jobs`, `GET /api/jobs/{job_id}`)를 구현했습니다.
    2.  **프론트엔드:** 작업 요청 후, `job_id`를 받아 주기적으로(Polling) 진행 상황을 확인하고, 사용자에게 진행률 바를 보여주며, 최종적으로 완료되었을 때 결과를 가져오는 로직으로 완전히 재작성했습니다.
  - **결과:** 이 아키텍처 변경을 통해 **타임아웃 문제를 근본적으로 해결**하고, 영상 길이에 상관없이 안정적으로 분석을 처리할 수 있는 전문가 수준의 시스템을 구축했습니다.