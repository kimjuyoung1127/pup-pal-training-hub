# 프로젝트 개요: AI 강아지 자세 분석 시스템 (V2)

## 1. 목표

YOLOv8 모델을 활용하여 사용자가 업로드한 동영상 속 강아지의 관절 움직임을 분석하고, 그 결과를 시각적으로 제공하는 웹 애플리케이션입니다. 이를 통해 반려견의 잠재적인 자세 문제를 조기에 발견하고 지속적으로 추적 관리할 수 있도록 돕는 것을 목표로 합니다.

---

## 2. 아키텍처의 진화: 문제 해결의 여정

이 프로젝트는 안정성과 확장성을 확보하기 위해 두 번의 중요한 아키텍처 변경을 거쳤습니다.

### V1: 초기 접근 - 서버 사이드 렌더링

-   **개념:** 백엔드 서버가 동영상 분석, 스켈레톤 렌더링, 최종 비디오 파일 인코딩까지 모든 것을 처리하고, 프론트엔드는 완성된 비디오를 재생만 하는 방식.
-   **문제점:**
    1.  **코덱 의존성:** 배포 환경(Docker)에 비디오 인코딩에 필요한 `H.264(avc1)` 코덱이 없어 `cv2.VideoWriter`가 실패하는 문제가 발생했습니다.
    2.  **서버 과부하:** 비디오 인코딩은 CPU를 많이 소모하여 Hugging Face 무료 티어의 제한된 리소스로는 처리 시간이 길고 불안정했습니다.
    3.  **치명적인 타임아웃:** 분석 및 인코딩 시간이 길어지자, 프론트엔드 또는 게이트웨이(Vercel/Netlify)에서 **최대 10초의 타임아웃**이 발생하여 `ERR_NETWORK` 오류가 반복되었습니다.

### V2: 최종 아키텍처 - 클라이언트 렌더링 + 비동기 작업 큐

위 문제들을 근본적으로 해결하기 위해, 서버와 클라이언트의 역할을 명확히 분리하는 현대적인 웹 아키텍처로 전면 전환했습니다.

-   **개념:**
    1.  **백엔드 (데이터 분석가):** AI 분석에만 집중하여, 관절 좌표 데이터(JSON)와 원본 영상의 URL만 제공합니다. 무거운 비디오 인코딩 작업을 완전히 제거했습니다.
    2.  **프론트엔드 (시각화 전문가):** 원본 영상을 `<video>` 태그로 재생하면서, 동시에 전달받은 좌표 데이터를 매 프레임마다 `<canvas>` 태그 위에 실시간으로 그려줍니다.
    3.  **비동기 통신:** 오래 걸리는 분석 작업을 백그라운드에서 처리하고, 프론트엔드는 '작업 ID'를 받아 주기적으로 진행 상황을 물어보는 **폴링(Polling)** 방식을 도입하여 타임아웃 문제를 원천적으로 해결했습니다.

-   **기대효과 (달성):**
    -   **서버 안정성 확보:** 코덱 의존성 및 인코딩 부하 제거.
    -   **응답성 향상:** 사용자는 분석 요청 후 즉시 응답을 받고, 진행 상황을 눈으로 확인할 수 있습니다.
    -   **확장성 증대:** 서버는 순수 계산에만 집중하므로, 향후 더 복잡한 분석 기능을 추가하기 용이합니다.

---

## 3. 핵심 기술 스택

-   **백엔드:** FastAPI, YOLOv8, OpenCV-Python (분석용), Uvicorn, Gunicorn
-   **프론트엔드:** React, Vite, TypeScript, Tailwind CSS, shadcn/ui, `html2canvas`
-   **배포:**
    -   **백엔드:** Hugging Face Spaces (Docker 기반)
    -   **프론트엔드:** Vercel / Netlify (가정)

---

## 4. 주요 기술적 과제 및 해결 과정

-   **CORS 오류:** `allow_origins=["*"]` 설정이 `allow_credentials=True`와 함께 사용될 때 발생하는 문제를 해결하기 위해, `mungai.co.kr` 등 허용할 출처를 명시적으로 지정하여 해결했습니다.
-   **환경 변수 문제:** 로컬(`localhost`)과 운영(`hf.space`) 환경의 API 주소가 달라 발생하는 `ERR_NETWORK` 오류를 해결하기 위해, `.env.development`와 `.env.production` 파일을 분리하고 `VITE_API_BASE_URL`을 동적으로 사용하도록 수정했습니다.
-   **혼합 콘텐츠 오류 (Mixed Content):** `https://` 페이지에서 `http://` 리소스를 차단하는 브라우저 보안 정책을 해결하기 위해, 백엔드에서 `x-forwarded-proto` 헤더를 확인하여 항상 `https://` URL을 생성하도록 로직을 수정했습니다.
-   **렌더링 경쟁 상태 (Race Condition):** 비디오의 크기 정보(`videoWidth`)가 로드되기 전에 렌더링을 시도하여 발생하던 '0으로 나누기' 오류를, `drawSkeletons` 함수 초입에 `if (video.videoWidth === 0) return;` 안전장치를 추가하여 해결했습니다.
-   **좌표계 불일치:** 원본 영상과 화면 표시 영상의 크기 차이로 스켈레톤이 벗어나는 문제를, `scale`과 `offset`을 정확히 계산하여 좌표를 변환하는 로직을 적용함으로써 해결했습니다. **(세로 영상 포함 완벽 지원)**

---

## 5. 현재 상태 및 향후 개발 계획

### 5.1. 현재 상태 (MVP)

-   **완료:** 클라이언트 렌더링 및 비동기 작업 큐 기반의 V2 아키텍처 구축 완료.
-   **성과:** 사용자가 동영상을 업로드하면, 타임아웃 없이 안정적으로 자세 분석이 수행되며, 가로/세로 영상 모두에서 스켈레톤이 정확한 위치에 렌더링됩니다.
-   **시각적 개선:** 렌더링되는 점과 선의 두께를 조절하여 강아지의 움직임이 더 잘 보이도록 개선했습니다.
-   **결론:** 프로젝트의 핵심 기능이 안정적으로 동작하는 MVP(Minimum Viable Product)가 완성되었습니다.

### 5.2. 향후 개발 계획 (Phase 2)

안정화된 MVP를 기반으로, 사용자 참여를 유도하고 서비스의 가치를 극대화하기 위한 다음 기능들을 개발합니다.

1.  **자세 안정성 점수화 시스템 도입:**
    -   **목표:** 분석 결과를 '안정성 점수'로 변환하여 사용자에게 게임과 같은 재미와 경쟁 요소를 제공합니다.
    -   **구현:** 백엔드에서 핵심 관절의 '미세 흔들림'을 측정하여 점수를 계산하고, API 응답에 `stability_score`를 추가합니다.

2.  **분석 결과의 영구 저장 및 조회:**
    -   **목표:** 모든 분석 결과를 Supabase DB에 영구적으로 저장하여, 사용자가 언제든지 자신의 분석 기록을 찾아보고 변화를 추적할 수 있게 합니다.
    -   **구현:**
        -   **백엔드:** 분석 완료 후, 결과 데이터(좌표, 영상 URL, 안정성 점수 등)를 `joint_analysis_records` 테이블에 저장하는 로직을 활성화/구현합니다.
        -   **프론트엔드:** `PostureAnalysisHistoryPage`에서 `useJointAnalysisHistory` 훅을 사용하여 DB에 저장된 전체 기록을 조회하고 표시합니다.

3.  **SNS 공유 카드 생성 기능:**
    -   **목표:** 단순 영상 다운로드를 넘어, 사용자가 자신의 분석 결과를 SNS에 자랑하고 싶게 만드는 매력적인 공유 기능을 제공합니다.
    -   **구현:**
        -   `PostureAnalysisHistoryPage`에서 특정 분석 기록을 선택합니다.
        -   `html2canvas` 라이브러리를 사용하여, 영상의 대표 프레임, 안정성 점수, 강아지 정보, 서비스 로고가 포함된 디자인된 '결과 카드'를 생성합니다.
        -   생성된 이미지를 PNG 파일로 즉시 다운로드하거나, 카카오톡 등 SNS로 공유하는 기능을 제공합니다.

4.  **데이터 전달 경로 개선:**
    -   **목표:** 분석 직후의 결과를 히스토리 페이지에 즉시 표시하여 사용자 경험의 연속성을 보장합니다.
    -   **구현:** `PostureAnalysisPage`에서 분석 완료 후 `localStorage`에 최신 결과를 임시 저장하고, `PostureAnalysisHistoryPage`는 로드 시 이 임시 데이터를 우선적으로 확인하여 화면 상단에 특별 카드로 표시합니다.